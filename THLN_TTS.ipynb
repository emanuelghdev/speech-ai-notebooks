{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Presentaci√≥n"
      ],
      "metadata": {
        "id": "xItZzoCs_-A2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "üëã Este cuaderno colab es un recurso generado por Zoraida Callejas y David Griol para la asignatura de [Tecnolog√≠as del habla y del Lenguaje Natural](https://masteres.ugr.es/desarrollo-software/docencia/plan-estudios/guia-docente/M52/56/5/23) del M√°ster de Desarrollo de Software de la Universidad de Granada. La primera parte del cuaderno es una adaptaci√≥n de la unidad 6 del curso Hugging Face Audio compartido [aqu√≠](https://huggingface.co/learn/audio-course/) y la descipci√≥n del modelo MMS de Facebook para espa√±ol compartido [aqu√≠](https://huggingface.co/facebook/mms-tts-spa). Dos recursos que te recomendamos investigar."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Siguiendo el cuaderno aprender√°s a:\n",
        "\n",
        "*   Utilizar **modelos pre-entrenados** basados en *deep learning* para la s√≠ntesis del habla.\n",
        "*   Guardar los audios generados en archivos wav.\n",
        "* Guardar archivos en tu Google Drive.\n",
        "\n",
        "Puedes ir sigui√©ndolo y ejecutando cada celda de c√≥digo secuencialmente."
      ],
      "metadata": {
        "id": "nk3SnhKB-jjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalaciones"
      ],
      "metadata": {
        "id": "1GCIh0_3VoL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comienza instalando los elementos que necesitar√°s. Seguramente algunos ya los tengas (en ese caso se mostrar√° \"Requirement already satisfied\")."
      ],
      "metadata": {
        "id": "2xmchtdV821X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install scipy"
      ],
      "metadata": {
        "id": "zrrlAOzfVqkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descarga del modelo TTS pre-entretenado"
      ],
      "metadata": {
        "id": "HgCW7hjiAY6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se propone comenzar con el modelo TTS **SpeechT5 de Microsoft** disponible en [HuggingFace](https://huggingface.co/docs/transformers/main/en/model_doc/speecht5). Se trata de un modelo de 2022, que vamos a usar en ingl√©s. Puedes leer m√°s sobre el modelo [aqu√≠](https://github.com/microsoft/SpeechT5?tab=readme-ov-file)."
      ],
      "metadata": {
        "id": "nAQ5sTGWTGhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech\n",
        "\n",
        "tokenizadorT5 = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
        "modeloT5 = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")"
      ],
      "metadata": {
        "id": "KFozmKHsSxwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokeniza\n",
        "\n"
      ],
      "metadata": {
        "id": "ffWKMb3ICz7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a tokenizar el texto que queremos sintetizar. Lo escribimos en ingl√©s porque desafortunadamente este modelo solo est√° disponible en ese idioma.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sQzzD2JlDShy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"I love learning about speech synthesis\"\n",
        "token_ids = tokenizadorT5(text=texto)\n",
        "\n",
        "#Imprimimos el valor num√©rico que se ha asociado a los tokens:\n",
        "print(\"Ids de los tokens\", token_ids.input_ids)\n",
        "\n",
        "#Imprimimos ahora el token original\n",
        "raw_tokens = [tokenizadorT5.decode([token_id]) for token_id in token_ids.input_ids]\n",
        "print(\"Raw tokens:\", raw_tokens)"
      ],
      "metadata": {
        "id": "HNNcRmuIUKnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al tokenizar puedes pedir que se generen tensores. Los tensores son objetos matem√°ticos que almacenan valores num√©ricos. Un tensor de dimensi√≥n 0 es un valor, de dimesnion 1 un vector, de dimension 2 una matriz... pudiendo tener m√°s de 3 dimensiones. Representan los datos de entrada, pesos, sesgos y valores de salida durante los procesos de entrenamiento e inferencia con redes neuronales.\n",
        "\n",
        "Distintos frameworks para deep learning generan distintos tipos de tensores. Usualmente es posible elegir entre 4:\n",
        "*   'pt' - Pytorch <-- Este es el que vamos utilizar\n",
        "*   'tf' - TensorFlow\n",
        "*   'np' - NumPy\n",
        "*   'jax' - JAX"
      ],
      "metadata": {
        "id": "EQBbd-0BQemy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "token_ids = tokenizadorT5(text=texto, return_tensors=\"pt\")\n",
        "input_ids = token_ids.input_ids\n",
        "print(input_ids)"
      ],
      "metadata": {
        "id": "jj6bixpoRN7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utiliza speaker embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "7z6TLjurWt0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con los speaker embeddings, puedes indicar qu√© voz o tipo de voz quieres para tu sintentizador. Se propone utilizar los embeddings compartidos [aqu√≠](https://huggingface.co/datasets/Matthijs/cmu-arctic-xvectors) correspondientes a las grabaciones de una base de datos de voces abierta [compartida por la Universidad Carnegie Mellon](http://www.festvox.org/cmu_arctic/)."
      ],
      "metadata": {
        "id": "AooGrN7iWzBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Cargamos el dataset, que est√° dividido en varios subconjuntos o \"splits\", utilizaremos el split de \"validation\"\n",
        "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "\n",
        "#Vamos a utilizar los embeddings de la voz 7306\n",
        "speaker_embeddings = embeddings_dataset[7306][\"xvector\"]\n",
        "\n",
        "#Lo convertimos en un tensor PyTorch\n",
        "speaker_embeddings = torch.tensor(speaker_embeddings).unsqueeze(0)\n",
        "\n",
        "print(speaker_embeddings)"
      ],
      "metadata": {
        "id": "vIVEj2WuW1f9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genera el audio"
      ],
      "metadata": {
        "id": "cS2of4vHVKrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬°Lleg√≥ el momento de generar el audio! üôå Para ello vas a usar los tensores y speaker embeddings que has generado en los pasos previos y adem√°s un vocoder. En este caso, se propone el vocoder [HiFi-GAN](https://huggingface.co/microsoft/speecht5_hifigan) de Microsoft.\n",
        "\n"
      ],
      "metadata": {
        "id": "s9RKZdpWgWg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5HifiGan\n",
        "\n",
        "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
        "habla = modeloT5.generate_speech(token_ids[\"input_ids\"], speaker_embeddings, vocoder=vocoder)"
      ],
      "metadata": {
        "id": "D1DEDQkpXfjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Escucha el resultado ü§û"
      ],
      "metadata": {
        "id": "DNBvUbic_Gwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(habla, rate=16000)"
      ],
      "metadata": {
        "id": "vZjlWu7oyZyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prueba un modelo que funcione en espa√±ol"
      ],
      "metadata": {
        "id": "G5ZpLNT8z1EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a repetir el proceso anterior con un modelo que admite espa√±ol. Para ello, vamos a usar el modelo **MMS-TTS de Facebook** [publicado en 2023](https://arxiv.org/abs/2305.13516). Puedes consultar [aqu√≠](https://dl.fbaipublicfiles.com/mms/misc/language_coverage_mms.html) el c√≥digo correspondiente a los idiomas que soporta. Para este cuaderno puedes usar el modelo en espa√±ol *mms-tts-spa*."
      ],
      "metadata": {
        "id": "ry9IfAzwkH2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VitsModel, VitsTokenizer\n",
        "import torch\n",
        "\n",
        "modeloMMS = VitsModel.from_pretrained(\"facebook/mms-tts-spa\")\n",
        "tokenizerMMS = VitsTokenizer.from_pretrained(\"facebook/mms-tts-spa\")\n",
        "\n",
        "token_ids = tokenizerMMS(\"Me interesan las tecnolog√≠as del habla\", return_tensors=\"pt\")\n",
        "input_ids = token_ids[\"input_ids\"]\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = modeloMMS(input_ids)\n",
        "\n",
        "hablaES = outputs[\"waveform\"]\n",
        "Audio(hablaES, rate=16000)"
      ],
      "metadata": {
        "id": "98-RznLKz9Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guarda el audio en un archivo wav"
      ],
      "metadata": {
        "id": "CHpJR745lGYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, genera el archivo wav usando *scipy*."
      ],
      "metadata": {
        "id": "gRfnDMAklg3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "import numpy as np\n",
        "\n",
        "output_array = hablaES[0].numpy()\n",
        "archivoAudio = \"MiPrimeraVozSintetica.wav\"\n",
        "scipy.io.wavfile.write(archivoAudio, rate=modeloMMS.config.sampling_rate, data=output_array)"
      ],
      "metadata": {
        "id": "FxrUQgJg2UOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guarda el archivo wav en Google Drive"
      ],
      "metadata": {
        "id": "U-jP_AGXn0lA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Te puede resultar interesante guardar el archivo en tu drive, a continuaci√≥n aprender√°s c√≥mo. Al ejecutar este trozo de c√≥digo, Google Colab pedir√° permiso para acceder a tu directorio Drive, deber√°s conceder los permisos para que funcione. Si no quieres hacerlo no hay problema, en este cuaderno mandas t√∫."
      ],
      "metadata": {
        "id": "pGbu-jvOmuDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "origen = 'MiPrimeraVozSintetica.wav'\n",
        "destino = '/content/drive/My Drive/MiPrimeraVozSintetica.wav'\n",
        "shutil.move(origen, destino)"
      ],
      "metadata": {
        "id": "_utwhchq3lr2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}